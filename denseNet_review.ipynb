{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p7FWmY18HWdO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, concatenate, BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "scheduler = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate = 0.001, decay_steps = 10000, decay_rate = 0.9)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train) , (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "C9sVGH1AIvN_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denseBlocks(x, growth_size, num_layers):\n",
        "  for _ in range(num_layers):\n",
        "    newBatch = BatchNormalization()(x)\n",
        "    newBatch = Activation(\"relu\")(x)\n",
        "    newBatch  = Conv2D(growth_size, (3,3), padding = \"same\")(x)\n",
        "    x = concatenate([x,newBatch])\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "\n",
        "def transitionBlocks(x):\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(32, (2,2), strides = 2)(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "EqDqjfyrI87X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  inputs = Input(shape = (32,32,3))\n",
        "\n",
        "  x  = Conv2D(32,(2,2))(inputs)\n",
        "  x = denseBlocks(x,16,3)\n",
        "\n",
        "\n",
        "  x  = transitionBlocks(x)\n",
        "\n",
        "  x = denseBlocks(x,8,3)\n",
        "\n",
        "  x = transitionBlocks(x)\n",
        "\n",
        "  x = denseBlocks(x, 4,2)\n",
        "\n",
        "\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "  x = tf.keras.layers.Dense(64)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = tf.keras.layers.Dense(32)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  outputs = tf.keras.layers.Dense(10,activation = \"softmax\")(x)\n",
        "  model = Model(inputs  =inputs, outputs = outputs)\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wGB9U8FRJ8Qa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "\n",
        "model = build_model()\n",
        "model.compile(optimizer = optimizer, loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2)\n",
        "assert  x_train.shape[0] == y_train.shape[0]\n",
        "assert  x_val.shape[0] == y_val.shape[0]\n",
        "history = model.fit(datagen.flow(x_train,y_train,batch_size = 128), epochs = 100, validation_data = (x_val,y_val), callbacks  = [EarlyStopping(monitor = \"val_loss\",min_delta = 0.01, patience = 10, verbose = 2, restore_best_weights = True)], verbose = 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvNUeZ0hPxSe",
        "outputId": "e2b9c9a9-32c8-42a2-a7c6-6e98788f71b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFI1-1XYPzNc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}